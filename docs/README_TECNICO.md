# üß† Sistema Inteligente de Reconocimiento Facial

## üßæ √çndice

0. [Resumen](#resumen)
1. [Introducci√≥n](#introducci√≥n)
2. [Acceso al stream RTSP](#acceso-al-stream-rtsp)
3. [Prueba inicial con c√°mara IP](#prueba-inicial-con-c√°mara-ip)
4. [Captura de im√°genes para dataset](#captura-de-im√°genes-para-dataset)
5. [Generaci√≥n de embeddings faciales](#generaci√≥n-de-embeddings-faciales)
6. [Reconocimiento facial en vivo](#reconocimiento-facial-en-vivo)
7. [Bot de Telegram: creaci√≥n y configuraci√≥n](#bot-de-telegram-creaci√≥n-y-configuraci√≥n)
8. [Sistema integral con Bot](#sistema-integral-con-bot)
9. [Sistema Inteligente de Reconocimiento Facial](#sistema-inteligente-de-reconocimiento-facial)
10. [Despliegue en VPS (AWS EC2)](#despliegue-en-vps-aws-ec2)
11. [L√≥gica del sistema](#l√≥gica-del-sistema)
12. [Trabajos a futuro](#trabajos-a-futuro)

---
## üßæ Resumen

El proyecto comenz√≥ con la necesidad de desarrollar un sistema de reconocimiento facial en tiempo real, capaz de identificar personas conocidas y detectar personas desconocidas, utilizando una c√°mara IP y t√©cnicas de visi√≥n por computadora. El primer paso fue establecer la conexi√≥n con una c√°mara Tapo C210 v√≠a protocolo RTSP, logrando capturar im√°genes desde Python con OpenCV.

A partir de estas im√°genes, se implement√≥ una rutina de recorte autom√°tico de rostros y se construy√≥ un dataset organizado por persona. Luego, se generaron los **embeddings faciales** utilizando la librer√≠a `face_recognition`, y se almacenaron como archivos `.pkl` para su uso posterior.

Con la base de datos armada, se desarroll√≥ un sistema de **detecci√≥n continua** que analiza cada frame en vivo, reconoce rostros conocidos y notifica su detecci√≥n mediante un bot de Telegram. Para los rostros no reconocidos, el sistema captura autom√°ticamente m√∫ltiples im√°genes, env√≠a una al chat y consulta si la persona es conocida. Si el usuario responde afirmativamente, se integran autom√°ticamente al sistema sin necesidad de reiniciar el script.

El flujo se consolid√≥ en un √∫nico archivo principal que gestiona captura, reconocimiento, aprendizaje asistido y notificaciones en tiempo real. Finalmente, el sistema fue desplegado en una **instancia EC2 de Amazon Web Services**, lo que permite que el c√≥digo se ejecute 24/7 de forma ininterrumpida. As√≠, el proyecto integra componentes de visi√≥n artificial, aprendizaje incremental y automatizaci√≥n en la nube, en una soluci√≥n robusta y extensible.

---
## Introducci√≥n

### üéØ **Objetivo General**

Desarrollar un sistema de reconocimiento facial en tiempo real utilizando una c√°mara IP, capaz de identificar personas conocidas y desconocidas, con integraci√≥n a Telegram para permitir interacci√≥n directa desde el chat. El sistema debe ser capaz de:

- Capturar rostros en vivo.
- Compararlos con una base de datos local (embeddings).
- Aprender nuevas identidades mediante supervisi√≥n humana.
- Ejecutarse 24/7 desde una VPS en la nube (Amazon EC2).

---

### üõ†Ô∏è **Fases del Desarrollo**

#### 1. **Prueba de conexi√≥n con la c√°mara IP**

- Se configur√≥ y accedi√≥ al stream RTSP de la c√°mara Tapo C210 desde Python usando OpenCV.
- Se verific√≥ que la conexi√≥n era estable y que se pod√≠a capturar frames en tiempo real.

#### 2. **Captura y creaci√≥n del dataset**

- Se desarroll√≥ un script para capturar im√°genes desde la c√°mara, recortar autom√°ticamente los rostros detectados, y almacenarlos en carpetas separadas por persona.
- Se cre√≥ la estructura de carpetas `dataset/NombrePersona/Nombre_1.jpg`, etc.

#### 3. **Generaci√≥n de embeddings**

- Se procesaron las im√°genes del dataset utilizando la librer√≠a `face_recognition`.
- Para cada rostro se gener√≥ un embedding (vector num√©rico) que se guard√≥ en un archivo `.pkl` por persona.
- Estos archivos se almacenaron en la carpeta `embeddings/`.

#### 4. **Reconocimiento facial en tiempo real**

- Se cre√≥ un bucle de detecci√≥n continua que:
    - Captura un frame desde la c√°mara.
    - Detecta todos los rostros presentes.
    - Compara cada uno con los embeddings guardados.

#### 5. **Integraci√≥n con Telegram Bot**

- Se configur√≥ un bot con `python-telegram-bot`.
- Cuando se detecta un rostro **desconocido**:
    - El sistema captura autom√°ticamente 20 im√°genes de esa persona.
    - Env√≠a la primera imagen al chat de Telegram.
    - El usuario responde "S√≠" o "No".
        - Si responde "S√≠", se pide un nombre, se guardan las im√°genes y se generan embeddings autom√°ticamente.
        - Si responde "No", las im√°genes son descartadas.
- Todo el proceso se realiza sin reiniciar el sistema.

#### 6. **Manejo de m√∫ltiples rostros**

- El sistema puede detectar y manejar m√∫ltiples personas al mismo tiempo.
- Cada rostro detectado es recortado individualmente y evaluado por separado.
- Las capturas y comparaciones son independientes por rostro.

#### 7. **Dise√±o del flujo completo**

- Se unificaron todos los scripts en uno solo (`cap_rostro.py`) que ejecuta:
    - Carga de embeddings.
    - Captura de video.
    - Detecci√≥n facial.
    - Comunicaci√≥n con Telegram.
    - Aprendizaje supervisado con nuevos usuarios.

#### 8. **Despliegue en la nube (Amazon VPS)**

- Se mont√≥ el sistema en una instancia EC2 de Amazon para ejecuci√≥n continua (24/7).
- El entorno virtual y las dependencias fueron configuradas.
- Se usa `tmux` o `screen` para dejar el script corriendo en segundo plano sin interrupciones.

---

### ‚öôÔ∏è **Funcionamiento General del Sistema**

1. El script se conecta a la c√°mara IP y empieza a capturar frames.
2. Se detectan todos los rostros presentes en cada frame.
3. Cada rostro se compara con los embeddings conocidos:
    - Si hay una coincidencia: se notifica por Telegram con la imagen y el nombre.
    - Si no hay coincidencia:
        - Se capturan 20 im√°genes de esa persona.
        - Se env√≠a la primera por Telegram.
        - El usuario responde si la conoce.
        - Si la persona es conocida, se genera su dataset y se crean embeddings nuevos autom√°ticamente, caso contrario las im√°genes se eliminan.

---

### üß© **Componentes del Proyecto**

- `cap_rostro.py`: script principal, integra todas las funcionalidades.
- `dataset/`: im√°genes recortadas por persona.
- `embeddings/`: vectores `.pkl` con los embeddings.
- `temp_unknown/`: carpeta temporal para almacenar im√°genes de desconocidos antes de clasificar.
- `Telegram bot`: interacci√≥n humana para decidir si se conoce o no a la persona.
- `Amazon VPS`: entorno de producci√≥n para ejecuci√≥n constante.

---

### üìå Notas importantes

- El sistema es **autoaprendizaje supervisado**: mejora a medida que se le indican nuevos rostros.
- Requiere red local estable y cuanto mejor sea la c√°mara mejor actuar√° el sistema.

---
## Acceso al stream RTSP

### üéØ ¬øQu√© es RTSP?

RTSP (Real Time Streaming Protocol) es un protocolo de red utilizado para transmitir video en tiempo real. La mayor√≠a de las c√°maras IP modernas (como TP-Link Tapo, Hikvision, Dahua, etc.) soportan este protocolo, lo que permite capturar video desde Python, VLC o herramientas de vigilancia.

---

### üßæ Formato general de una URL RTSP

```

rtsp://<usuario>:<contrase√±a>@<ip>:<puerto>/<ruta>
```

- `<usuario>`: nombre de usuario configurado en la c√°mara.
- `<contrase√±a>`: contrase√±a asociada.
- `<ip>`: direcci√≥n IP local de la c√°mara.
- `<puerto>`: normalmente es `554`, el puerto est√°ndar RTSP.
- `<ruta>`: depende del modelo (puede ser `stream1`, `h264`, `video`, etc.).

---

### üõ†Ô∏è C√≥mo obtener la URL RTSP de tu c√°mara

#### üì± Opci√≥n 1: Usando la app oficial

Para c√°maras Tapo, por ejemplo:

1. Entr√° a la app **TP-Link Tapo**.
2. Activ√° la opci√≥n **"Habilitar transmisi√≥n RTSP"** (suele estar en "Configuraci√≥n avanzada" o "Configuraci√≥n de grabaci√≥n").
3. Defin√≠ un **usuario y contrase√±a** para el stream.
4. Te mostrar√° la URL completa (copiala).

#### üñ•Ô∏è Opci√≥n 2: Usar software como VLC

1. Instal√° **VLC Media Player**.
2. En el men√∫, and√° a: `Medio > Abrir ubicaci√≥n de red`.
3. Peg√° una posible URL RTSP con tus credenciales:
    
    ```
    
    rtsp://usuario:contrase√±a@IP:554/stream1
    ```
    
4. Si se conecta, entonces es v√°lida y pod√©s usarla en Python.

#### üîç Opci√≥n 3: Consultar documentaci√≥n oficial del fabricante

Cada marca tiene su propia estructura de URL RTSP. Busc√° en Google:

`<modelo de tu c√°mara> RTSP URL`

---

### ‚ö†Ô∏è Notas

- Asegurate de que la c√°mara est√© **conectada a la misma red local** que tu PC o VPS (salvo que tengas configurado acceso externo).
- Si us√°s una **VPS como Amazon EC2**, vas a necesitar configurar un t√∫nel o acceso remoto (VPN, reenv√≠o de puertos o DDNS).
- No compartas p√∫blicamente tu URL RTSP con usuario y contrase√±a.

---
## Prueba inicial con c√°mara IP

### üéØ Objetivo

Verificar que se puede acceder a la c√°mara Tapo (u otra IP) desde Python utilizando el protocolo RTSP y capturar correctamente un fotograma para su visualizaci√≥n.

---

### üß© Descripci√≥n del c√≥digo

Este script (`cam_test.py`) realiza una conexi√≥n b√°sica al stream de la c√°mara usando OpenCV. Luego intenta capturar un solo frame y mostrarlo como imagen RGB mediante `PIL`.

---

### ‚úÖ Resultados esperados

- Se abre una **ventana emergente** con el fotograma capturado.
- En consola se muestra: `‚úÖ Stream en vivo. Presion√° Ctrl+C para frenar.`
- Si hay un error de conexi√≥n: `‚ùå No se pudo conectar al stream.`

---

### üîç Observaciones

- Este script **no guarda im√°genes**, solo verifica si el acceso al stream funciona correctamente.
- Pod√©s modificar `for _ in range(1)` a un n√∫mero mayor si quer√©s ver m√∫ltiples frames en bucle.
- Este fue el **primer paso del proyecto**, y sirvi√≥ como base para construir el pipeline de captura de rostros en tiempo real.

---
## Captura de im√°genes para dataset

Una vez verificada la conexi√≥n con la c√°mara IP a trav√©s de RTSP, el siguiente paso fue desarrollar un script (`img_capture`) que permitiera **capturar m√∫ltiples im√°genes de una persona** y guardarlas localmente para luego generar los embeddings faciales.

---

### üéØ Objetivo

Construir un **dataset personalizado de rostros**, donde cada persona tenga su propia carpeta con varias im√°genes capturadas autom√°ticamente desde el stream de la c√°mara.

---

### ‚öôÔ∏è Funcionamiento general

El script realiza los siguientes pasos:

1. **Establece conexi√≥n con la c√°mara IP** utilizando la URL RTSP.
2. Solicita o recibe como par√°metro el nombre de la persona a capturar.
3. Crea una carpeta espec√≠fica dentro de `dataset/` con el nombre ingresado (si no existe).
4. **Captura autom√°ticamente m√∫ltiples im√°genes** (por defecto 20), con una pausa configurable entre cada toma (por defecto 3 segundos).
5. Guarda cada imagen en la carpeta correspondiente con un nombre como `Persona_1.jpg`, `Persona_2.jpg`, etc.

---

### üß† ¬øPor qu√© m√∫ltiples im√°genes?

Capturar varias im√°genes en diferentes momentos permite tener **variabilidad en expresiones, √°ngulos e iluminaci√≥n**, lo cual es fundamental para mejorar la precisi√≥n del reconocimiento facial m√°s adelante.

---

### üóÇÔ∏è Estructura generada

Luego de correr el script, la estructura de carpetas queda as√≠:

```

face_detection_system/
‚îî‚îÄ‚îÄ dataset/
    ‚îú‚îÄ‚îÄ Juan/
    ‚îÇ   ‚îú‚îÄ‚îÄ Juan_1.jpg
    ‚îÇ   ‚îú‚îÄ‚îÄ Juan_2.jpg
    ‚îÇ   ‚îî‚îÄ‚îÄ ...
    ‚îî‚îÄ‚îÄ Ana/
        ‚îú‚îÄ‚îÄ Ana_1.jpg
        ‚îî‚îÄ‚îÄ ...
```

Cada subcarpeta representa una persona conocida, y contiene im√°genes capturadas autom√°ticamente.

---

### üîß Par√°metros personalizables

En el script se pueden ajustar f√°cilmente:

- `person_name`: nombre de la persona (se convierte en el nombre de la carpeta).
- `num_images`: cantidad de im√°genes a capturar (por defecto 20).
- `interval`: segundos entre cada captura (por defecto 3 segundos).

---

### ‚úÖ Buenas pr√°cticas

- Es recomendable que la persona est√© **bien iluminada y centrada** al momento de capturar las im√°genes.
- Si se detecta ruido o im√°genes borrosas, pueden eliminarse manualmente de la carpeta.
- Pod√©s repetir la captura m√°s adelante si quer√©s mejorar el dataset para esa persona.

---
## Generaci√≥n de embeddings faciales

Una vez capturadas las im√°genes para cada persona, el siguiente paso en el sistema es convertir esas im√°genes en **vectores num√©ricos (embeddings)**, por medio del script `generate_embeddings.py`, que representen matem√°ticamente los rasgos faciales. Estos vectores permiten comparar rostros entre s√≠ y realizar reconocimiento facial con precisi√≥n.

---

### üéØ Objetivo

Extraer, a partir de las im√°genes de cada persona, un conjunto de **embeddings faciales** y almacenarlos como archivos `.pkl`. Estos archivos luego se cargan r√°pidamente al iniciar el sistema para comparar en tiempo real los rostros detectados con la base conocida.

---

### üß† ¬øQu√© es un embedding facial?

Un *embedding* es un **vector de caracter√≠sticas** que resume la informaci√≥n clave de un rostro (forma de ojos, nariz, boca, mand√≠bula, etc.). Este vector tiene normalmente 128 dimensiones y permite comparar rostros mediante **distancias euclidianas**.

---

### ‚öôÔ∏è Funcionamiento general del script

1. **Carga todas las subcarpetas** de la carpeta `dataset/` (una por persona).
2. Recorre todas las im√°genes de cada persona.
3. Para cada imagen:
    - Detecta los rostros presentes.
    - Extrae los embeddings del rostro principal.
    - Si el embedding es v√°lido, lo guarda en una lista.
4. Cuando termina con todas las im√°genes de esa persona, **guarda los embeddings en un archivo `.pkl`** dentro de la carpeta `embeddings/`.
5. Si ya existe un `.pkl` para esa persona, se omite para evitar duplicados innecesarios.

---

### üíæ Estructura de salida esperada

Luego de correr este proceso, se obtiene una carpeta con un archivo `.pkl` por persona, por ejemplo:

```

face_detection_system/
‚îî‚îÄ‚îÄ embeddings/
    ‚îú‚îÄ‚îÄ Juan.pkl
    ‚îú‚îÄ‚îÄ Ana.pkl
    ‚îî‚îÄ‚îÄ Pedro.pkl
```

Cada archivo `.pkl` contiene un diccionario con:

- `encodings`: una lista de embeddings (vectores NumPy).
- `name`: nombre de la persona correspondiente.

---

### üöß Manejo de errores y validaciones

- Si una imagen no contiene ning√∫n rostro, se omite.
- Si la imagen est√° corrupta o en un formato no v√°lido, el error se informa pero no detiene el script.
- Se evita procesar personas que ya tengan su archivo `.pkl` generado.

---

### üìå Consideraciones

- Se utiliza el modelo `"hog"` para la detecci√≥n de rostros, que es m√°s liviano y r√°pido que `"cnn"`, aunque menos preciso.
- S√≥lo se guarda el **primer rostro detectado** en cada imagen para evitar errores por im√°genes con m√∫ltiples personas.
- Es posible ejecutar este script varias veces sin problema; los embeddings ya generados no se sobrescriben a menos que se borren manualmente.

---
## Reconocimiento facial en vivo

Una vez generados los embeddings faciales, el siguiente paso es realizar **detecci√≥n en tiempo real** (`live_compare.py`). Este m√≥dulo permite capturar un frame desde la c√°mara IP, detectar los rostros presentes, compararlos con la base conocida y mostrar visualmente el resultado del reconocimiento.

---

### üéØ Objetivo

Detectar rostros en vivo a partir de un fotograma capturado desde la c√°mara, compararlos con los embeddings previamente generados, y mostrar por pantalla el nombre de la persona reconocida o marcarla como "Desconocido".

---

### ‚öôÔ∏è ¬øC√≥mo funciona el proceso?

El pipeline consta de **tres etapas principales**:

### 1. **Carga de embeddings**

- Se leen todos los archivos `.pkl` de la carpeta `embeddings/`.
- Se extraen:
    - Los vectores de caracter√≠sticas (`encodings`)
    - Los nombres correspondientes a cada vector

### 2. **Captura de frame**

- Se conecta moment√°neamente a la c√°mara IP v√≠a RTSP.
- Se obtiene un √∫nico fotograma (`frame`), que ser√° procesado para an√°lisis facial.

### 3. **Reconocimiento facial**

- Se convierte la imagen BGR a RGB (formato esperado por `face_recognition`).
- Se detectan todos los rostros presentes en el frame.
- Por cada rostro detectado:
    - Se genera su embedding.
    - Se compara con todos los embeddings registrados utilizando `compare_faces`.
    - Si se encuentra una coincidencia (dentro de una tolerancia definida), se asigna el nombre correspondiente.
    - Si no hay coincidencia, se marca como **"Desconocido"**.
- Se dibujan cuadros alrededor de los rostros detectados y se etiquetan con el nombre.
- El resultado se muestra con `matplotlib`.

---

### üß™ ¬øQu√© devuelve este m√≥dulo?

Una imagen renderizada que incluye:

- Cuadro verde sobre cada rostro detectado.
- Nombre de la persona si fue reconocida.
- La etiqueta **"Desconocido"** si no coincide con nadie en la base de datos.

Adem√°s, se imprime en el t√≠tulo de la imagen la lista de nombres reconocidos.

---

### üß© Consideraciones t√©cnicas

- Se utiliza una tolerancia de `0.4` para el reconocimiento facial. Bajos valores hacen el sistema m√°s estricto (menos falsos positivos), pero pueden generar falsos negativos.
- S√≥lo se captura un frame por ejecuci√≥n. Para detecci√≥n continua o en tiempo real, ser√≠a necesario integrarlo en un bucle.
- El reconocimiento se realiza **en memoria** usando los embeddings precargados, lo cual es eficiente.
- Se usa `matplotlib` en lugar de `cv2.imshow()` para mayor compatibilidad y est√©tica al visualizar im√°genes.

---

### ‚úÖ Requisitos previos

- Haber generado previamente los archivos `.pkl` con embeddings.
- Tener im√°genes bien iluminadas y centradas en el dataset mejora significativamente la precisi√≥n del sistema.

---
## Bot de Telegram: creaci√≥n y configuraci√≥n

Para que tu sistema de reconocimiento facial pueda **enviarte alertas e interactuar con vos**, necesit√°s crear un **bot personalizado de Telegram**. Este bot ser√° tu asistente automatizado, capaz de enviarte fotos, hacerte preguntas, y aprender nuevas caras seg√∫n tus respuestas.

---

### üßæ PASO A PASO para generar tu bot

#### 1. **Abr√≠ Telegram y busc√° a `@BotFather`**

- Este es el **asistente oficial** de Telegram para crear bots.
- Revis√° que sea el oficial con el tic de verificaci√≥n.

#### 2. **Inici√° la conversaci√≥n**

- Escrib√≠ el comando:
    
    ```
    
    /start
    ```
    
    Te va a mostrar una lista de comandos disponibles.
    

#### 3. **Cre√° un nuevo bot**

- Escrib√≠:
    
    ```
    
    /newbot
    ```
    
- Luego te pedir√°:
    1. **Nombre del bot** (puede tener espacios, por ejemplo: `Bot de Seguridad`)
    2. **Nombre de usuario √∫nico** para el bot (debe terminar en `bot`, por ejemplo: `SeguridadDeCasaBot`)

> ‚ö†Ô∏è Si el nombre de usuario ya est√° en uso, te pedir√° que elijas otro. No puede haber dos bots con el mismo handle.
> 

#### 4. **Obten√© tu token**

- Una vez creado, BotFather te responde con un mensaje como este:
    
    ```
    
    Done! Congratulations on your new bot. You will find it at t.me/SeguridadDeCasaBot.
    Use this token to access the HTTP API:
    123456789:ABCdefGHIjklMNOpqrSTUvwxYZ123456789
    ```
    
- **Guard√° este token**, ya que lo vas a necesitar para integrarlo con tu sistema (`TELEGRAM_TOKEN`).

---

### üì• ¬øC√≥mo obtener tu `chat_id`?

Para que el bot sepa a qui√©n enviar los mensajes (o fotos), necesit√°s tu `chat_id`. Para obtenerlo:

#### Opci√≥n r√°pida:

1. Envi√° cualquier mensaje a tu bot (por ejemplo, escrib√≠ ‚Äúhola‚Äù).
2. Abr√≠ este enlace en tu navegador (reemplaz√° el token por el tuyo):

```

https://api.telegram.org/bot<TELEGRAM_TOKEN>/getUpdates
```

1. Vas a ver una respuesta en formato JSON. Busc√° una parte como esta:

```json

"chat": {
  "id": 123456789,
  "first_name": "Nombre",
  ...
}

```

- **Ese n√∫mero (`123456789`) es tu `CHAT_ID`**.

> Pod√©s usar herramientas como jsonformatter.org si quer√©s que el resultado sea m√°s legible.
> 

---

### ‚úÖ ¬øQu√© necesit√°s entonces para que tu sistema funcione?

| Variable | ¬øDe d√≥nde la sac√°s? | Ejemplo |
| --- | --- | --- |
| `TELEGRAM_TOKEN` | De BotFather al crear el bot | `123456789:ABCdefGHIjklMNOpqrSTUvwxYZ123456789` |
| `CHAT_ID` | De la respuesta JSON de Telegram | `123456789` |

---

### üìå Consejos de seguridad

- Nunca publiques tu token ni chat ID en repositorios p√∫blicos.
- Guardalos en un archivo `.env` y cargalos desde el c√≥digo usando librer√≠as como `python-dotenv`.

---
## Sistema integral con Bot

Este m√≥dulo es el **n√∫cleo inteligente del sistema** (`bot_master.py`), que integra m√∫ltiples componentes para lograr una **detecci√≥n y gesti√≥n automatizada de rostros en vivo**, interactuando con el usuario mediante un **bot de Telegram**. El sistema se ejecuta en tiempo real y est√° preparado para correr de forma continua en una VPS, permitiendo identificar personas conocidas y gestionar rostros desconocidos desde el celular.

---

### üß† Componentes principales del sistema

1. **üì° Streaming en vivo desde la c√°mara IP (Tapo u otra)**
2. **üß† Reconocimiento facial asincr√≥nico** basado en embeddings generados previamente
3. **ü§ñ Interacci√≥n v√≠a Telegram bot**, que permite tomar decisiones humanas en tiempo real
4. **üì• Acumulaci√≥n ordenada de personas desconocidas en espera**
5. **üìÇ Autoentrenamiento y aprendizaje continuo de nuevos rostros a trav√©s del bot**

---

### üß© ¬øC√≥mo funciona el sistema completo?

#### 1. **Inicializaci√≥n y carga de embeddings**

- Se cargan todos los embeddings `.pkl` desde la carpeta `embeddings/`.
- Se generan dos listas:
    - `known_face_encodings`: vectores de caracter√≠sticas
    - `known_face_names`: etiquetas de cada persona

#### 2. **Captura y reconocimiento facial continuo**

- Se inicia un **hilo paralelo (`threading`)** que ejecuta en bucle:
    - Captura un frame desde la c√°mara RTSP.
    - Detecta rostros en la imagen.
    - Compara cada rostro con los embeddings conocidos.
    - Si es un rostro reconocido:
        - Env√≠a una foto al usuario por Telegram con su nombre y hora.
        - Aplica un retardo m√≠nimo configurable (`DELAY_NOTIFICACION_MIN`) para evitar spam.
    - Si es un rostro **no reconocido**:
        - Se captura autom√°ticamente una serie de im√°genes (por defecto, 20).
        - Se asigna un ID temporal (ej: `desconocido_3`) y se acumula en una **cola de espera**.

#### 3. **Interacci√≥n por Telegram con el bot**

- Al detectar un desconocido:
    - Se env√≠a al usuario una primera imagen con una pregunta:
        
        **"¬øConoc√©s a esta persona? (S√≠ / No)"**
        
- Seg√∫n la respuesta del usuario:
    - **"No"**: se eliminan las im√°genes y se ignora el caso.
    - **"S√≠"**: el bot pide que el usuario escriba el nombre.
        - Luego mueve las im√°genes a la carpeta del dataset correspondiente.
        - Genera autom√°ticamente los embeddings para esa persona.
        - Los guarda como un nuevo `.pkl` y actualiza la base.
        - El nuevo rostro ya queda disponible para reconocimiento en vivo.

---

### üîÑ Flujo resumido

```

1. Captura frame desde c√°mara
2. Detecta rostros y compara con base conocida
3. Si conocido ‚Üí foto + mensaje a Telegram
4. Si desconocido:
   - Captura m√∫ltiple de im√°genes
   - Env√≠a imagen + pregunta al usuario
   - Espera decisi√≥n (S√≠/No)
   - Si "S√≠" ‚Üí pide nombre ‚Üí entrena nuevo rostro
   - Si "No" ‚Üí descarta im√°genes
```

---

### üß∞ Herramientas y librer√≠as usadas

- `face_recognition`: detecci√≥n y generaci√≥n de embeddings faciales
- `OpenCV (cv2)`: captura de im√°genes desde c√°mara RTSP
- `Telegram Bot API`: env√≠os autom√°ticos de im√°genes y mensajes
- `asyncio + threading`: ejecuci√≥n concurrente (detecci√≥n + interacci√≥n sin bloqueos)
- `pickle`: almacenamiento binario de embeddings
- `shutil`: gesti√≥n de archivos e im√°genes temporales

---

### üí¨ Comandos soportados por el bot

- `/start`: inicia el bot y confirma que est√° escuchando
- Mensajes:
    - `"S√≠"`: habilita la carga de nombre para autoentrenamiento
    - `"No"`: descarta a la persona desconocida
    - `"Juan"`, `"Luc√≠a"`, etc.: etiqueta del nuevo rostro a incorporar

---

## Sistema Inteligente de Reconocimiento Facial

### üéØ Versi√≥n Final Documentada

Este sistema (`cap_rostro.py`) permite **detectar rostros en tiempo real** desde una **c√°mara Tapo v√≠a RTSP**, identificar personas conocidas, **interactuar con un bot de Telegram** en caso de desconocidos, y realizar **autoentrenamiento incremental**, permitiendo que el sistema **aprenda de sus errores y se vuelva m√°s preciso con el tiempo**.

---

### üì¶ Funcionalidades incluidas

| Componente | Descripci√≥n |
| --- | --- |
| üì° **Streaming en vivo desde Tapo** | Conexi√≥n directa mediante RTSP para capturar im√°genes cada pocos segundos. |
| üß† **Reconocimiento facial m√∫ltiple** | Detecta y reconoce **varias personas en un mismo frame**. |
| üß© **Identificaci√≥n de desconocidos** | Si un rostro no coincide con ning√∫n embedding conocido, lo considera "desconocido". |
| ü§ñ **Interacci√≥n v√≠a Telegram Bot** | Env√≠a la imagen del desconocido al chat y pregunta si se lo reconoce. |
| üì• **Acumulaci√≥n ordenada** | Se almacenan temporalmente 20 capturas distintas por persona desconocida. |
| üóÇÔ∏è **Auto-entrenamiento incremental** | Si el usuario indica que el rostro es conocido, las im√°genes se suman al dataset existente, y el sistema **actualiza autom√°ticamente los embeddings**. |
| ‚ôªÔ∏è **Reutilizaci√≥n de desconocidos** | Si el sistema **detecta que ya hab√≠a visto al mismo desconocido antes**, **no lo duplica ni vuelve a preguntar**. Esto se hace mediante comparaci√≥n por distancia facial. |
| üß† **Aprendizaje de errores** | Si reconoce err√≥neamente a alguien conocido como desconocido, ahora se puede **reforzar su dataset** sumando nuevas im√°genes desde Telegram. |
| üßº **Limpieza autom√°tica** | Desconocidos que no tienen suficientes im√°genes v√°lidas son descartados autom√°ticamente. |

---

### ‚öôÔ∏è M√≥dulos y estructuras clave

#### üîç `deteccion()`

- Corre en un hilo aparte y se encarga de:
    - Capturar im√°genes desde la c√°mara Tapo.
    - Detectar rostros en el frame.
    - Comparar contra el banco de rostros conocidos (`known_face_encodings`).
    - Evitar duplicados de desconocidos usando `face_distance()` con un umbral (`< 0.4`).
    - Enviar la primera captura al bot y esperar respuesta.

#### üß† `recibir_mensaje()`

- Escucha las respuestas del usuario v√≠a Telegram.
- Si se responde ‚ÄúS√≠‚Äù, solicita un nombre y:
    - Mueve las im√°genes al dataset.
    - Genera embeddings nuevos desde cero para esa persona.
    - Actualiza `known_face_encodings` autom√°ticamente.
    - Evita tener que reentrenar todo el sistema desde cero.
- Si se responde ‚ÄúNo‚Äù, descarta el bloque de im√°genes.

#### üì¶ `generar_embeddings_para(nombre)`

- Se ejecuta tambi√©n como **subproceso separado** al actualizar una persona.
- Recorre todas las im√°genes en la carpeta de ese nombre y genera sus embeddings (si detecta rostro).

---

#### üß† Manejo inteligente de desconocidos

| Caso | ¬øQu√© hace el sistema? |
| --- | --- |
| Vuelve a aparecer el mismo desconocido | No lo duplica. Compara con `encodings_desconocidos_vivos`. |
| Aparece otro rostro al mismo tiempo | Detecta y maneja m√∫ltiples en paralelo. |
| Rostro conocido detectado mal como desconocido | Si el usuario responde "S√≠" y le pone el nombre correcto, el sistema suma las im√°genes al dataset y mejora la precisi√≥n futura. |
| No se detecta rostro en un frame | Lo ignora y no guarda la imagen (previene ruido y falsos positivos). |
| No se llega a capturar al menos 3 fotos v√°lidas | Descarta autom√°ticamente la carpeta de ese desconocido. |

---

### üìÅ Estructura de carpetas    

```

üìÅ dataset/           ‚Üí Carpetas con im√°genes por persona conocida
üìÅ embeddings/        ‚Üí Archivos .pkl con embeddings por persona
üìÅ temp_unknown/      ‚Üí Carpetas temporales por desconocido detectado
```

---
## Despliegue en VPS (AWS EC2)

---

### ü™ú Paso 1: Crear una cuenta en AWS

1. Ir a https://aws.amazon.com/
2. Crear una cuenta gratuita (te pedir√° una tarjeta de cr√©dito, pero hay capa gratuita por 12 meses)
3. Verific√° tu identidad, agreg√° un m√©todo de pago y seleccion√° el plan **Free Tier**

---

### ü™ú Paso 2: Crear una instancia EC2 (VPS)

1. Ir a la consola de AWS: https://console.aws.amazon.com/
2. En la barra de b√∫squeda, pon√© **EC2** y seleccion√° el servicio.
3. Click en **‚ÄúLaunch Instance‚Äù** (Lanzar nueva instancia).
4. Eleg√≠ lo siguiente:
    - **Nombre**: `reconocimiento-facial`
    - **AMI**: Ubuntu Server 22.04 LTS (Free tier elegible)
    - **Tipo de instancia**: `t2.micro` (gratis)
    - **Par de claves (Key pair)**: Crear uno nuevo y **descargar el archivo `.pem`**
    - **Almacenamiento**: 8-10 GB (suficiente)
    - **Firewall**: habilit√° el puerto **22 (SSH)**
5. Click en **Launch Instance**

---

### ü™ú Paso 3: Conectarse por SSH a la VPS

1. Asegurate de tener el archivo `.pem` descargado en tu m√°quina.
2. Abr√≠ una terminal y corr√©:

```bash

chmod 400 tu_archivo.pem
ssh -i "tu_archivo.pem" ubuntu@<IP_PUBLICA_DE_TU_EC2>

```

üìå *La IP p√∫blica la pod√©s copiar desde el panel de AWS (instancias EC2 > tu instancia).*

---

### ü™ú Paso 4: Preparar la VPS (instalar dependencias)

Una vez conectado por SSH:

```bash

sudo apt update && sudo apt upgrade -y
sudo apt install python3-pip python3-opencv python3-dev build-essential cmake git unzip curl -y
pip install --upgrade pip
pip install face_recognition opencv-python-headless telegram python-telegram-bot

```

‚ö†Ô∏è *Si da error por `dlib`, instal√° estas libs primero:*

```bash

sudo apt install libdlib-dev libboost-all-dev -y
pip install dlib

```

---

### ü™ú Paso 5: Subir tu proyecto a la VPS

Desde tu computadora local:

```bash

scp -i "tu_archivo.pem" -r ./mi_proyecto ubuntu@<IP_PUBLICA_EC2>:~

```

Reemplaz√° `mi_proyecto` con la carpeta donde tengas tu script final, datasets y carpetas asociadas.

---

### ü™ú Paso 6: Probar que el sistema funcione

Una vez en la VPS:

```bash

cd mi_proyecto
python3 sistema.py

```

Si todo funciona (y el RTSP de la c√°mara es accesible desde la red de la VPS), deber√≠a empezar a detectar rostros y enviar notificaciones por Telegram.

---

### ü™ú Paso 7: Hacer que corra 24/7 autom√°ticamente (systemd)

Aunque vos uses Windows, **la VPS corre Linux**, y **s√≠ puede usar `systemd`**.

Solo segu√≠ estos pasos **conectado por SSH a la VPS** (desde Windows us√°s PuTTY o PowerShell):

1. Crear un servicio de Linux que lo mantenga siempre corriendo:

```bash

sudo nano /etc/systemd/system/reconocimiento.service

```

1. Peg√° esto dentro:

```

[Unit]
Description=Sistema de reconocimiento facial
After=network.target

[Service]
User=ubuntu
WorkingDirectory=/home/ubuntu/mi_proyecto
ExecStart=/usr/bin/python3 sistema.py
Restart=always

[Install]
WantedBy=multi-user.target

```

1. Guardar y salir (`Ctrl + O`, Enter, `Ctrl + X`)
2. Activar y arrancar:

```bash

sudo systemctl daemon-reexec
sudo systemctl daemon-reload
sudo systemctl enable reconocimiento.service
sudo systemctl start reconocimiento.service

```

1. Ver logs del sistema (opcional):

```bash

journalctl -u reconocimiento.service -f

```

---

### ü™ú Paso 8: Qu√© hacer si quer√©s actualizar algo

1. Conectate por SSH a la VPS
2. Naveg√° a la carpeta del proyecto
3. Hac√© los cambios (pod√©s subir archivos v√≠a `scp` de nuevo si quer√©s)
4. Reinici√° el servicio:

```bash

sudo systemctl restart reconocimiento.service

```

---

### üí° Tips √∫tiles

- üì∏ Asegurate que la c√°mara **Tapo sea accesible desde la red de la VPS**. Si no lo es, deber√≠as instalar la VPS en la misma red local (con Raspberry o similar), o usar una VPN para unir redes.
- üîê El `TELEGRAM_TOKEN` y `CHAT_ID` pueden guardarse en un archivo `.env` y usarse v√≠a `os.getenv()` para m√°s seguridad.
- ‚õëÔ∏è Si quer√©s monitorear el estado del sistema, pod√©s crear un log o canal de Telegram exclusivo para errores y alertas internas.

---

### ‚úÖ Resultado Final

Una vez desplegado, el sistema:

- Estar√° corriendo **aunque tu computadora est√© apagada**.
- Iniciar√° autom√°ticamente cada vez que la VPS se reinicie.
- Estar√° listo para reconocer rostros, aprender de errores y enviar mensajes por Telegram de forma aut√≥noma.

---
## L√≥gica del sistema

Esta secci√≥n describe paso a paso la l√≥gica de funcionamiento del sistema de reconocimiento facial en vivo con interacci√≥n v√≠a Telegram bot, detecci√≥n multiusuario y autoaprendizaje incremental.

---

### 1. üì° Captura y preprocesamiento

- Se conecta a una **c√°mara IP v√≠a RTSP** para obtener im√°genes en tiempo real.
- Por cada frame:
    - Se **detectan todos los rostros** presentes mediante `face_recognition`.
    - Cada rostro se **recorta individualmente** antes de ser procesado, evitando contaminaci√≥n con otros rostros en la imagen.
    - Se calcula su **encoding facial** (vector que representa el rostro).

---

### 2. üß† Comparaci√≥n con base de datos

- Se cargan desde disco los **embeddings de personas conocidas** previamente entrenadas (`.pkl`).
- Cada nuevo rostro detectado se compara contra la base usando `face_recognition.compare_faces()` con una tolerancia ajustada.

---

### 3. ‚úÖ Detecci√≥n de persona conocida

- Si el encoding coincide con uno ya existente:
    - Se **verifica si ya fue notificado recientemente** (para evitar spam).
    - En caso contrario, se env√≠a una **notificaci√≥n autom√°tica al Telegram bot** con:
        
        ```
        
        ‚úÖ Nombre fue detectado el DD/MM/AAAA HH:MM:SS
        ```
        
    - La foto del rostro tambi√©n se adjunta.

---

### 4. üïµÔ∏è‚Äç‚ôÇÔ∏è Detecci√≥n de desconocido

- Si el encoding no coincide con ninguno en la base:
    - Se verifica que no sea un **desconocido repetido** (mismo encoding dentro de cierta tolerancia). Si ya fue detectado, se ignora.
    - Si es nuevo, se le asigna un ID tipo `desconocido_1`, se crea una carpeta temporal y se **capturan 20 im√°genes (como m√°ximo, ya que pueden ser menos de 20 pero m√°s 3) del rostro** con 2 segundos entre cada una.
    - Solo se guardan im√°genes donde el rostro detectado coincide con el encoding inicial que dispar√≥ la detecci√≥n, **evitando contaminaci√≥n por detecci√≥n m√∫ltiple**.
    - En caso de que la carpeta solo tenga 3 o menos fotos (por alg√∫n motivo el sistema no logr√≥ tomar las fotos necesarias), esta se elimina autom√°ticamente.

---

### 5. üì• Cola de desconocidos

- Si hay varios desconocidos detectados en momentos cercanos, el sistema **encola los desconocidos** y solo notifica uno a la vez (hasta que el usuario responda por el primer desonocido).
- El bot env√≠a al usuario:
    
    ```
    
    üïµÔ∏è Se detect√≥ una persona desconocida (desconocido_1) el DD/MM/AAAA HH:MM:SS
    ‚ùì ¬øConoc√©s a esta persona? (S√≠ / No)
    ```
    
- El usuario puede responder:
    - `"No"` ‚Üí Se eliminan las im√°genes capturadas de `desconocido_1`.
    - `"S√≠"` ‚Üí El bot solicita el nombre.

---

### 6. ‚úèÔ∏è Etiquetado y entrenamiento incremental

- Si el usuario responde `"S√≠"`:
    - El bot solicita: `"‚úèÔ∏è Ingres√° el nombre de la persona:"`
    - Se renombra la carpeta temporal con ese nombre y se **mueve al dataset**.
    - Se generan autom√°ticamente los nuevos **embeddings faciales** (`.pkl`) y se actualiza la base de datos en memoria.
    - Si ya exist√≠a una carpeta con ese nombre (por ejemplo, el sistema fall√≥ en reconocerlo), las im√°genes nuevas se **sumar√°n a esa carpeta**, robusteciendo el reconocimiento.

---

### 7. üîÑ Autoaprendizaje y mejora continua

- El sistema es **autoentrenable** desde el chat. No requiere comandos manuales.
- Permite corregir falsos negativos: si un rostro ya registrado fue mal clasificado como desconocido, se puede **reasignar con su nombre original** y se regeneran los embeddings, mejorando la precisi√≥n futura.
- Las detecciones y los embeddings se recargan peri√≥dicamente (cada 10 segundos), asegurando que los nuevos datos est√©n disponibles sin reiniciar el sistema.

---

### 8. üîÅ Robustez ante m√∫ltiples rostros

- En escenarios con varias personas delante de la c√°mara:
    - Se procesan todos los rostros detectados en cada frame.
    - Para los desconocidos, se mantiene **aislado el seguimiento** de cada individuo:
        - Se guarda s√≥lo el rostro que coincide con el que dispar√≥ la detecci√≥n.
        - As√≠ se evita que fotos de varias personas terminen en la misma carpeta de entrenamiento.

---

### 9. üîÉ Detecci√≥n continua y ejecuci√≥n aut√≥noma

- Corre en un hilo paralelo (thread) desde una VPS.
- Puede funcionar indefinidamente sin intervenci√≥n.
- El bot responde autom√°ticamente ante nuevas detecciones, decisiones del usuario y aprendizaje de nuevos rostros.

---

### ‚úÖ Resultado: Sistema inteligente y aut√≥nomo

El sistema:

- Aprende continuamente de sus errores.
- Mejora su precisi√≥n con el tiempo.
- Est√° preparado para funcionar **de manera 100% remota**, sin necesidad de tener la computadora personal encendida.
- Tiene una l√≥gica de decisi√≥n limpia, robusta y con prevenci√≥n de duplicados o errores de clasificaci√≥n.

---
## Trabajos a futuro

### ‚úÖ Estado actual del sistema

El sistema permite:

- üì° Captura de video en vivo desde una c√°mara Tapo v√≠a RTSP.
- üß† Reconocimiento facial en tiempo real usando `face_recognition`.
- ü§ñ Interacci√≥n asincr√≥nica v√≠a Telegram bot (`python-telegram-bot`).
- üßç‚Äç‚ôÇÔ∏è Acumulaci√≥n ordenada de personas desconocidas (sin duplicar).
- ‚úçÔ∏è Posibilidad de asignar nombres a desconocidos y autoincluirlos en el dataset.
- üîÅ Auto-actualizaci√≥n de embeddings en tiempo real.
- üë• Reconocimiento de m√∫ltiples rostros en el mismo frame.
- üöÄ Corre de forma aut√≥noma en una VPS, incluso si la PC personal est√° apagada.

---

### üå± Mejoras futuras (potenciales evoluciones)

#### 1. üîê Seguridad y privacidad

- Encriptar el almacenamiento de im√°genes sensibles.
- Implementar autenticaci√≥n para acceder al sistema desde otros canales (web, app).
- Agregar logs de acceso e historial de detecciones.

#### 2. üí° Inteligencia mejorada

- Implementar una red neuronal m√°s robusta (ej. FaceNet + clasificaci√≥n SVM o deep metric learning).
- Evaluar modelos alternativos con `torch`, `tensorflow` o `InsightFace` para mayor precisi√≥n.
- Agregar tolerancia a √°ngulos de c√°mara o baja luz usando aumentaci√≥n de datos.

#### 3. üìä Interfaz de monitoreo

- Crear un dashboard web (Flask/FastAPI + Dash/Plotly) con:
    - Historial de detecciones
    - Estad√≠sticas por persona
    - Capturas archivadas
    - Visualizaci√≥n en tiempo real

#### 4. üìÅ Gesti√≥n avanzada de dataset

- Herramienta gr√°fica para revisar, renombrar y organizar dataset de im√°genes.
- Eliminar autom√°ticamente im√°genes borrosas o duplicadas.

#### 5. üì≤ Multicanal

- Integrar otros canales: WhatsApp (via Twilio), Discord, WebSockets.
- Crear una Progressive Web App (PWA) para notificaciones push desde el celular.

#### 6. üß™ Testing & tolerancia a fallos

- Agregar tests autom√°ticos (unitarios/integraci√≥n) con `pytest`.
- Registrar errores en logs persistentes (archivos `.log`).

#### 7. üß† Autoaprendizaje y feedback

- Permitir al sistema reevaluar detecciones pasadas y ajustar la base de datos.
- Sistema de reputaci√≥n/confianza para embeddings (m√°s im√°genes = mayor peso).

#### 8. üîÑ Modo entrenamiento continuo

- Recopilar autom√°ticamente im√°genes nuevas de conocidos para mejorar sus embeddings con el tiempo.
- Detectar cu√°ndo un rostro conocido no se reconoce por cambios (barba, gafas, etc.) y permitir "refuerzo".

---

### üõ†Ô∏è Posibles tecnolog√≠as futuras a evaluar

| Tecnolog√≠a | Prop√≥sito |
| --- | --- |
| **InsightFace** | Reconocimiento facial ultra preciso y veloz |
| **DeepFace** | Framework de alto nivel con varios backends (Facenet, Dlib, etc.) |
| **ONNX Runtime** | Optimizaci√≥n y aceleraci√≥n en producci√≥n |
| **Flask/FastAPI** | API web liviana y escalable |
| **React / Next.js** | Frontend moderno si se crea interfaz web |
| **Docker** | Contenerizaci√≥n para f√°cil despliegue |
| **Supervisor** | Alternativa a `systemd` para manejo de procesos |

---

### üóÇÔ∏è Notas adicionales

- Automatizar backups del dataset a la nube (Google Drive, S3).
- Agregar m√©tricas de rendimiento: detecciones/hora, latencia promedio, etc.

---

### üß† Visi√≥n a futuro

> ‚ÄúConvertir este sistema en una plataforma extensible para vigilancia inteligente, con capacidad de escalar, aprender con el tiempo y adaptarse a entornos variados (hogares, empresas, instituciones).‚Äù
>